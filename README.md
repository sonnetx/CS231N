# Finetuning Pretrained Models for Compressed Dermatology Image Analysis

This project explores how compressed and degraded dermatology images (from the ISIC 2019 dataset) affect classification performance using pretrained vision models. It compares fine-tuning vs. linear probing across multiple JPEG quality levels.

![System architecture diagram](<./CS231N Poster.png>)

## Project Goals

- Evaluate model robustness to image compression (JPEG 90/50/20)
- Compare pretrained models: ViT, DINOv2, and SimCLR
- Benchmark fine-tuning vs. linear probing
- Analyze FLOPs, GPU memory, and classification accuracy

## Models

- `ViT`: Vision Transformer from Hugging Face
- `DINOv2`: Self-supervised ViT from Meta
- `SimCLR`: Contrastive ResNet50 trained with linear classifier

## Metrics Tracked

- Accuracy, F1 Score, AUC
- FLOPs (GFLOPs)
- GPU memory usage
- Training and evaluation time

## Project Structure

```
CS231N/
â”œâ”€â”€ configs/                         
â”‚   â””â”€â”€ example_config.yaml          # Configs for job submissions
â”‚
â”œâ”€â”€ scripts/                         # Lightweight utility or shell scripts
â”‚   â”œâ”€â”€ download_unpack_isic2019.sh  # Downloads and unpacks ISIC data
â”‚   â””â”€â”€ submit_from_config.sh        # SLURM submission helper
â”‚
â”œâ”€â”€ jobs/                            # SLURM-related job definitions
â”‚   â””â”€â”€ job_template.slurm
â”‚
â”œâ”€â”€ src/                             # Source code, logically grouped
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ finetune/                    # Fine-tuning workflows
â”‚   â”‚   â””â”€â”€ baseline_finetuning.py
â”‚   â”œâ”€â”€ evaluation/                  # Evaluation + plotting
â”‚   â”‚   â””â”€â”€ evaluate_isic_results.py
â”‚   â””â”€â”€ models/                      # Model-related scripts
â”‚       â”œâ”€â”€ model_comparison.py      # Config file with constant strings
â”‚       â”œâ”€â”€ model_comparison.py
â”‚       â””â”€â”€ model_comparison_2.py

â”‚
â”œâ”€â”€ results/                         # Auto-generated results
â”‚   â”œâ”€â”€ plots/                       # Accuracy/f1/AUC plots
â”‚   â””â”€â”€ logs/                        # Training logs or SLURM outputs
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .github
â””â”€â”€ README.md   
```

## Quick Start

1. Install requirements:
   ```bash
   pip install -r requirements.txt
   ```

2. Run training:
   ```bash
   python train_models.py
   ```

3. View results
   We use weights and biases for logging, so output plots can be seen there

## ðŸ“¦ Dataset

- [ISIC 2019 (Hugging Face)](https://huggingface.co/datasets/MKZuziak/ISIC_2019_224)
